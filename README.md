# Smart City Streaming Data Pipeline ğŸš¦ğŸ™ï¸

Proyek ini merupakan bagian dari portofolio data engineering yang dirancang untuk menyimulasikan dan memproses data streaming dalam konteks **Smart City** menggunakan Apache Kafka dan Apache Spark.

## ğŸ§  Deskripsi Proyek

Proyek ini menyimulasikan arus data dari berbagai sensor kota pintar (GPS kendaraan, kamera lalu lintas, cuaca, dan insiden darurat) dan memprosesnya secara real-time menggunakan Spark Structured Streaming. Data dikirim melalui Kafka, lalu disimpan dalam format Parquet ke AWS S3.

### Komponen Utama:
- **Data Simulation**: Generator data Python yang menghasilkan data kendaraan, GPS, cuaca, kamera lalu lintas, dan insiden.
- **Kafka Cluster**: Infrastruktur berbasis Docker menggunakan Kafka, Zookeeper, dan broker.
- **Spark Streaming**: Spark membaca data real-time dari Kafka, melakukan parsing schema, dan menyimpannya ke AWS S3.
- **Docker Compose**: Mengorkestrasi seluruh layanan secara terintegrasi.

---

## ğŸ—‚ï¸ Struktur Proyek

```bash
.
â”œâ”€â”€ data_engineering/
â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”œâ”€â”€ main.py              # Generator data streaming
â”‚   â”‚   â”œâ”€â”€ config.py            # Konfigurasi environment AWS
â”‚   â”‚   â””â”€â”€ spark-city.py        # Pipeline streaming Spark
â”‚   â””â”€â”€ docker-compose.yml       # Orkestrasi Kafka, Spark, dll.
â”œâ”€â”€ DE_SCity/
â”‚   â””â”€â”€ jobs/
â”‚       â””â”€â”€ try.py               # Eksperimen lain
â”œâ”€â”€ image/                       # Folder gambar/visualisasi (jika ada)
â”œâ”€â”€ requirements.txt             # Dependencies Python
â””â”€â”€ README.md
```

##âš™ï¸ Teknologi yang Digunakan
- **Komponen  Teknologi
- Data Generator  Python + Confluent Kafka
- Messaging	Apache Kafka + Zookeeper (via Docker)
- Stream Process	Apache Spark Structured Streaming (3.5.0)
- Penyimpanan	AWS S3 (via Hadoop AWS Connector)
- Orkestrasi	Docker Compose
